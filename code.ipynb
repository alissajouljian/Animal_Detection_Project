{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b50a142",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 21:24:19.409992: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten \n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7351b661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/cat\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/dog\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/elephant\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/chicken\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/cow\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/sheep\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/spider\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/horse\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/squirrel\n",
      "done fitting\n",
      "done splitting\n"
     ]
    }
   ],
   "source": [
    "# Directory where the images are located\n",
    "dataset_dir = \"/Users/alissa/Desktop/1_Practice/9.4/raw-img\"\n",
    "\n",
    "# List of animal classes\n",
    "animal_classes = ['cat', 'dog', 'elephant', 'chicken', 'cow', 'sheep', 'spider', 'horse', 'squirrel']\n",
    "\n",
    "# Lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop over each animal class\n",
    "for animal_class in animal_classes:\n",
    "    # Create the path to the class directory\n",
    "    class_dir = os.path.join(dataset_dir, animal_class)\n",
    "    print(class_dir)\n",
    "    \n",
    "    # Loop over each image file in the class directory\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        # Create the full image path\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        \n",
    "        # Load the image and resize it to (224, 224)\n",
    "        image = load_img(image_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        # Append the image and label to the respective lists\n",
    "        images.append(image)\n",
    "        labels.append(animal_class)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode the labels with numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "print('done fitting')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "print('done splitting')\n",
    "\n",
    "# Normalize the pixel values to the range [0, 1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoded vectors\n",
    "train_labels_one_hot = to_categorical(train_labels, num_classes=9)\n",
    "test_labels_one_hot = to_categorical(test_labels, num_classes=9)\n",
    "\n",
    "# Define the input shape for the model\n",
    "input_shape = (224, 224, 3)\n",
    "input_tensor = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d7fcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "22/22 [==============================] - 1952s 87s/step - loss: 0.8427 - accuracy: 0.7649 - val_loss: 0.2194 - val_accuracy: 0.9435\n",
      "Epoch 2/7\n",
      "22/22 [==============================] - 1951s 89s/step - loss: 0.1658 - accuracy: 0.9536 - val_loss: 0.1622 - val_accuracy: 0.9578\n",
      "Epoch 3/7\n",
      "22/22 [==============================] - 2114s 97s/step - loss: 0.1182 - accuracy: 0.9635 - val_loss: 0.1548 - val_accuracy: 0.9585\n",
      "Epoch 4/7\n",
      "22/22 [==============================] - 2774s 128s/step - loss: 0.0891 - accuracy: 0.9734 - val_loss: 0.1464 - val_accuracy: 0.9605\n",
      "Epoch 5/7\n",
      "22/22 [==============================] - 2489s 114s/step - loss: 0.0701 - accuracy: 0.9796 - val_loss: 0.1306 - val_accuracy: 0.9630\n",
      "Epoch 6/7\n",
      "22/22 [==============================] - 2573s 119s/step - loss: 0.0541 - accuracy: 0.9853 - val_loss: 0.1336 - val_accuracy: 0.9645\n",
      "Epoch 7/7\n",
      "22/22 [==============================] - 1923s 88s/step - loss: 0.0393 - accuracy: 0.9897 - val_loss: 0.1351 - val_accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5ba397670>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained InceptionV3 model without the top classification layer\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Pass the input tensor through the base model\n",
    "x = base_model(input_tensor)\n",
    "\n",
    "# Add additional layers on top of the base model\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Add the final classification layer with 9 output units (one for each animal class)\n",
    "predictions = Dense(9, activation='softmax')(x)\n",
    "\n",
    "# Create the model with the input tensor as input and predictions as output\n",
    "model = Model(inputs=input_tensor, outputs=predictions)\n",
    "\n",
    "# Freeze the weights of the base model (do not update them during training)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with Adam optimizer, categorical cross-entropy loss, and accuracy metric\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels_one_hot,\n",
    "    batch_size=900,\n",
    "    epochs=7,\n",
    "    validation_data=(test_images, test_labels_one_hot)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed0efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"model_inception.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d438414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931bcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c35d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a493de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ae55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d79733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808d1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
