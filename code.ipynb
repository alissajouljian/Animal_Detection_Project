{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b50a142",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 21:24:19.409992: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten \n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7351b661",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/cat\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/dog\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/elephant\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/chicken\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/cow\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/sheep\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/spider\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/horse\n",
      "/Users/alissa/Desktop/1_Practice/9.4/raw-img/squirrel\n",
      "done fitting\n",
      "done splitting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_dir = \"/Users/alissa/Desktop/1_Practice/9.4/raw-img\"\n",
    "\n",
    "animal_classes = ['cat', 'dog', 'elephant', 'chicken', 'cow', 'sheep', 'spider', 'horse', 'squirrel']\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for animal_class in animal_classes:\n",
    "    class_dir = os.path.join(dataset_dir, animal_class)\n",
    "    print(class_dir)\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        image = load_img(image_path, target_size=(224, 224))  # Adjust the target size as per your requirements\n",
    "        image = img_to_array(image)\n",
    "        images.append(image)\n",
    "        labels.append(animal_class)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "print('done fitting')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "print('done splitting')\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "\n",
    "train_labels_one_hot = to_categorical(train_labels, num_classes=9)\n",
    "test_labels_one_hot = to_categorical(test_labels, num_classes=9)\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "input_tensor = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d7fcf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "22/22 [==============================] - 1952s 87s/step - loss: 0.8427 - accuracy: 0.7649 - val_loss: 0.2194 - val_accuracy: 0.9435\n",
      "Epoch 2/7\n",
      "22/22 [==============================] - 1951s 89s/step - loss: 0.1658 - accuracy: 0.9536 - val_loss: 0.1622 - val_accuracy: 0.9578\n",
      "Epoch 3/7\n",
      "22/22 [==============================] - 2114s 97s/step - loss: 0.1182 - accuracy: 0.9635 - val_loss: 0.1548 - val_accuracy: 0.9585\n",
      "Epoch 4/7\n",
      "22/22 [==============================] - 2774s 128s/step - loss: 0.0891 - accuracy: 0.9734 - val_loss: 0.1464 - val_accuracy: 0.9605\n",
      "Epoch 5/7\n",
      "22/22 [==============================] - 2489s 114s/step - loss: 0.0701 - accuracy: 0.9796 - val_loss: 0.1306 - val_accuracy: 0.9630\n",
      "Epoch 6/7\n",
      "22/22 [==============================] - 2573s 119s/step - loss: 0.0541 - accuracy: 0.9853 - val_loss: 0.1336 - val_accuracy: 0.9645\n",
      "Epoch 7/7\n",
      "22/22 [==============================] - 1923s 88s/step - loss: 0.0393 - accuracy: 0.9897 - val_loss: 0.1351 - val_accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5ba397670>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# x = base_model.output\n",
    "x = base_model(input_tensor)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)  \n",
    "x = MaxPooling2D((3, 3))(x)  \n",
    "x = Flatten()(x)  \n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(9, activation='softmax')(x)  \n",
    "\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels_one_hot,\n",
    "    batch_size=900,\n",
    "    epochs=7, \n",
    "    validation_data =(test_images, test_labels_one_hot)\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55661928",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_inception.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9f3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cb324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c48fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302142b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57639804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2096b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808d1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
